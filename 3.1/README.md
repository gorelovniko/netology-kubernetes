# Домашнее задание к занятию «Компоненты Kubernetes» - `Горелов Николай`


## 1. Расчёт общих ресурсов приложений

### База данных
- 3 реплики
- 4 ГБ ОЗУ × 3 = **12 ГБ**
- 1 ядро × 3 = **3 CPU**

### Кеш (Redis / Memcached и т.п.)
- 3 реплики
- 4 ГБ ОЗУ × 3 = **12 ГБ**
- 1 ядро × 3 = **3 CPU**

### Фронтенд
- 5 реплик
- 50 МБ ОЗУ × 5 = **250 МБ ≈ 0.25 ГБ**
- 0.2 ядра × 5 = **1 CPU**

### Бекенд
- 10 реплик
- 600 МБ ОЗУ × 10 = **6000 МБ = 6 ГБ**
- 1 ядро × 10 = **10 CPU**

### Итого по приложениям:
- **ОЗУ**: 12 + 12 + 0.25 + 6 = **30.25 ГБ**
- **CPU**: 3 + 3 + 1 + 10 = **17 CPU**

---

## 2. Учёт DaemonSet и системных компонентов

Согласно [learnk8s.io](https://learnk8s.io/kubernetes-node-size), на каждом узле работают системные компоненты:
- kubelet + ОС
- kube-proxy
- log collector (Fluent Bit и т.п.)
- NodeLocal DNSCache
- CSI-драйверы

Эти компоненты потребляют фиксированные ресурсы **на каждый узел**, независимо от его размера.

Ориентировочно:
- **CPU**: ~70–100 м (0.07–0.1 ядра)
- **RAM**: ~1–1.5 ГБ

Также необходимо учесть **eviction threshold** — ~100 МБ RAM.

Для расчётов будем использовать **консервативную оценку**:
- **1.5 ГБ RAM + 0.1 CPU на ноду** для системных нужд.

---

## 3. Выбор архитектуры: количество и размер нод

### Требования к отказоустойчивости
- База данных и кеш: 3 реплики → должны быть распределены минимум по **3 разным нодам**, чтобы отказ одной ноды не убил более одной реплики.
- То же касается бекенда и фронтенда: для HA лучше иметь **минимум 3 ноды**, но для запаса — **4 ноды**, чтобы выдержать выход из строя одной.

> **Вывод**: минимальное количество рабочих нод = **4** (чтобы при потере одной осталось ≥3).

---

## 4. Расчёт ресурсов на ноду

Общие ресурсы приложений:  
- **RAM**: 30.25 ГБ  
- **CPU**: 17 ядер

Разделим равномерно на 4 ноды (с учётом, что приложение может быть распределено неравномерно, но планируем равномерную загрузку):

- **RAM на ноду**: 30.25 / 4 ≈ **7.56 ГБ**
- **CPU на ноду**: 17 / 4 ≈ **4.25 ядер**

Добавим системные нужды на ноду:
- RAM: 7.56 + 1.5 ≈ **9.06 ГБ**
- CPU: 4.25 + 0.1 ≈ **4.35 ядер**

Теперь учтём **запас на случай выхода из строя одной ноды**. При потере одной ноды оставшиеся 3 должны выдержать всю нагрузку:

- **RAM на оставшуюся ноду**: 30.25 / 3 ≈ **10.08 ГБ** + 1.5 ГБ = **11.58 ГБ**
- **CPU на оставшуюся ноду**: 17 / 3 ≈ **5.67 ядер** + 0.1 = **5.77 ядер**

→ Следовательно, **каждая нода должна иметь как минимум**:
- **12 ГБ RAM**
- **6 ядер CPU**

(округляем вверх до ближайших стандартных значений)

---

## 5. Выбор типа ноды

В облаке (например, GCP, AWS, Azure) типичные варианты:

- **n1-standard-8** (GCP): 8 vCPU, 30 ГБ RAM — избыточен по RAM
- **n1-standard-4**: 4 vCPU, 16 ГБ RAM — **не хватает CPU** (нужно ≥6)
- **n1-standard-6**: 6 vCPU, 24 ГБ RAM — **подходит**, но не во всех облаках есть
- **n2-standard-8**: 8 vCPU, 32 ГБ RAM — перебор

Более реалистично использовать:
- **4 ноды по 8 vCPU и 16–24 ГБ RAM**

Но можно и сэкономить, если использовать **6 vCPU и 16 ГБ RAM** — этого достаточно с запасом.

> Однако, учитывая, что в облаках часто нет инстансов с 6 ядрами, возьмём **8 vCPU и 16 ГБ RAM** как ближайший стандартный вариант.

---

## 6. Итоговые требования к кластеру

- **Количество рабочих нод**: **4**
- **Тип каждой ноды**: **8 vCPU, 16 ГБ RAM**
- **Общая ёмкость кластера**:
  - CPU: 4 × 8 = **32 vCPU**
  - RAM: 4 × 16 = **64 ГБ**
- **Доступно для подов** (после вычета системных):
  - RAM: ~64 − (4 × 1.5) ≈ **58 ГБ** → достаточно (нужно 30.25 ГБ)
  - CPU: ~32 − (4 × 0.1) ≈ **31.6 ядер** → достаточно (нужно 17)

При выходе из строя одной ноды:
- Останется 3 × 8 = **24 vCPU**, 3 × 16 = **48 ГБ RAM**
- После системных: ~43.5 ГБ RAM, ~23.7 CPU → **всё ещё достаточно**

---

## 7. Дополнительно: рекомендации по чарту

- Использовать **Helm-чарт** с параметризацией:
  - `replicaCount` для каждого компонента
  - `resources.requests/limits` согласно указанным цифрам
- Для базы и кеша — использовать **StatefulSet** с `podAntiAffinity` (requiredDuringScheduling), чтобы гарантировать размещение реплик на разных нодах.
- Для бекенда/фронтенда — **Deployment** с аналогичной `podAntiAffinity` (preferred или required).
- Включить **PodDisruptionBudget** для критичных компонентов (база, кеш, бекенд).

---

✅ **Вывод**:  
Для отказоустойчивого размещения приложения с учётом всех требований и запаса на отказ одной ноды требуется **4 рабочих ноды**, каждая с **8 vCPU и 16 ГБ оперативной памяти**.